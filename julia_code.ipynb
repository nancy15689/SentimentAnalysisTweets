{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using DataFrames, Plots, CSV, LowRankModels\n",
    "# load data\n",
    "train = CSV.read(\"train_input.csv\"; types=[Int, Int, Int,Int,Int, Float64, Float64, Float64,Float64,Int]);\n",
    "test = CSV.read(\"test_input.csv\"; types=[Int, Int, Int,Int,Int, Float64, Float64, Float64,Float64,Int]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "proxgrad_const (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import LowRankModels: evaluate, grad\n",
    "evaluate(loss::Loss, X::Array{Float64,2}, w::Array{Float64,1}, y) = evaluate(loss, X*w, y)\n",
    "grad(loss::Loss, X::Array{Float64,2}, w::Array{Float64,1}, y) = X'*grad(loss, X*w, y)\n",
    "evaluate(loss::Loss, X::Array{Float64,2}, w::Array{Float64,2}, y) = evaluate(loss, X*w, y)\n",
    "grad(loss::Loss, X::Array{Float64,2}, w::Array{Float64,2}, y) = X'*grad(loss, X*w, y)\n",
    "\n",
    "is_differentiable(l::QuadLoss) = true\n",
    "is_differentiable(l::L1Loss) = false\n",
    "is_differentiable(l::HuberLoss) = true\n",
    "is_differentiable(l::QuantileLoss) = false\n",
    "is_differentiable(l::PoissonLoss) = true\n",
    "is_differentiable(l::WeightedHingeLoss) = false\n",
    "is_differentiable(l::LogisticLoss) = true\n",
    "is_differentiable(l::OrdinalHingeLoss) = false\n",
    "is_differentiable(l::OrdisticLoss) = true\n",
    "is_differentiable(l::MultinomialOrdinalLoss) = true\n",
    "is_differentiable(l::BvSLoss) = is_differentiable(l.bin_loss)\n",
    "is_differentiable(l::MultinomialLoss) = true\n",
    "is_differentiable(l::OvALoss) = is_differentiable(l.bin_loss)\n",
    "is_differentiable(l::PeriodicLoss) = true\n",
    "\n",
    "function proxgrad(loss::Loss, args...; kwargs...)\n",
    "  return proxgrad_linesearch(loss, args...; kwargs...)\n",
    "  # if is_differentiable(loss)\n",
    "  #   return proxgrad_linesearch(loss, args...; kwargs...)\n",
    "  # else\n",
    "  #   return proxgrad_dec(loss, args...; kwargs...)\n",
    "  # end\n",
    "end\n",
    "\n",
    "function proxgrad_linesearch(loss::Loss, reg::Regularizer, X::Array{Float64,2}, y;\n",
    "                  maxiters = 100,\n",
    "                  stepsize = 1,\n",
    "                  w = (embedding_dim(loss)==1 ? zeros(size(X,2)) : zeros(size(X,2), embedding_dim(loss))),\n",
    "                  ch = ConvergenceHistory(\"proxgrad\"))\n",
    "    update_ch!(ch, 0, evaluate(loss, X, w, y) + evaluate(reg, w))\n",
    "    t = time()\n",
    "    for i=1:maxiters\n",
    "        # gradient\n",
    "        g = grad(loss, X, w, y)\n",
    "        # prox gradient step\n",
    "        neww = prox(reg, w - stepsize*g, stepsize)\n",
    "        # record objective value\n",
    "        curobj = evaluate(loss, X, neww, y) + evaluate(reg, neww)\n",
    "        if curobj > ch.objective[end]\n",
    "          stepsize *= .5\n",
    "        else\n",
    "          copy!(w, neww)\n",
    "          t, told = time(), t\n",
    "          update_ch!(ch, t - told, curobj)\n",
    "        end\n",
    "    end\n",
    "    return w\n",
    "end\n",
    "\n",
    "function proxgrad_dec(loss::Loss, reg::Regularizer, X::Array{Float64,2}, y;\n",
    "                  maxiters = 100,\n",
    "                  stepsize = 1,\n",
    "                  w = (embedding_dim(loss)==1 ? zeros(size(X,2)) : zeros(size(X,2), embedding_dim(loss))),\n",
    "                  ch = ConvergenceHistory(\"proxgrad\"),\n",
    "                  verbose = true)\n",
    "    wbest = copy(w)\n",
    "    update_ch!(ch, 0, evaluate(loss, X, w, y) + evaluate(reg, w))\n",
    "    t = time()\n",
    "    if verbose\n",
    "      println(\"using decreasing stepsize for nondifferentiable loss\")\n",
    "    end\n",
    "    for i=1:maxiters\n",
    "        # gradient\n",
    "        g = grad(loss, X, w, y)\n",
    "        # prox gradient step\n",
    "        w = prox(reg, w - stepsize/i*g, stepsize/i)\n",
    "        # record objective value\n",
    "        obj = evaluate(loss, X, w, y) + evaluate(reg, w)\n",
    "        if obj < ch.objective[end]\n",
    "          if verbose\n",
    "            println(\"found a better obj $obj\")\n",
    "          end\n",
    "          copy!(wbest, w)\n",
    "          update_ch!(ch, time() - t, obj)\n",
    "        end\n",
    "    end\n",
    "    return wbest\n",
    "end\n",
    "\n",
    "function proxgrad_const(loss::Loss, reg::Regularizer, X::Array{Float64,2}, y;\n",
    "                  maxiters = 100,\n",
    "                  stepsize = 1,\n",
    "                  w = (embedding_dim(loss)==1 ? zeros(size(X,2)) : zeros(size(X,2), embedding_dim(loss))),\n",
    "                  ch = ConvergenceHistory(\"proxgrad\"))\n",
    "    wbest = copy(w)\n",
    "    update_ch!(ch, 0, evaluate(loss, X, w, y) + evaluate(reg, w))\n",
    "    t = time()\n",
    "    for i=1:maxiters\n",
    "        # gradient\n",
    "        g = grad(loss, X, w, y)\n",
    "        # prox gradient step\n",
    "        w = prox(reg, w - stepsize*g, stepsize)\n",
    "        # record objective value\n",
    "        obj = evaluate(loss, X, w, y) + evaluate(reg, w)\n",
    "        if obj < ch.objective[end]\n",
    "          copy!(wbest, w)\n",
    "          update_ch!(ch, time() - t, obj)\n",
    "        end    end\n",
    "    return wbest\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "squaredError (generic function with 1 method)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errorRate(prediction, labels) = sum(abs.(sign.(prediction) - sign.(labels)) / 2.0) / size(labels,1)\n",
    "squaredError(prediction, labels) = sum(abs2.(prediction - sign.(testy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# least squares regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getElements(a) = get(a)\n",
    "n = size(X,1)\n",
    "X = convert(Array, train[1:size(train, 1), 6:(size(train, 2) - 1)]);\n",
    "y = convert(Array, train[1:size(train, 1), end:end]);\n",
    "X = getElements.(X)\n",
    "y = getElements.(y)\n",
    "X = [X ones(n)]\n",
    "y = y[:]\n",
    "size(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       "  0.0143044 \n",
       " -0.00726158\n",
       "  0.0207852 \n",
       " -0.0206557 \n",
       "  0.00134724"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# least squares regression\n",
    "w_quad = proxgrad(QuadLoss(), ZeroReg(), X, y, maxiters=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testX = convert(Array, test[1:size(test, 1), 6:(size(test, 2) - 1)]);\n",
    "testy = convert(Array, test[1:size(test, 1), end:end]);\n",
    "testX = [getElements.(testX) ones(size(testX,1))]\n",
    "testy = getElements.(testy)\n",
    "test_pred = sign.(testX*w_quad);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30919220055710306\n",
      "338.9134471630731\n"
     ]
    }
   ],
   "source": [
    "println(errorRate(testX*w_quad, testy))\n",
    "println(squaredError(testX*w_quad, testy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33msumabs2(x) is deprecated, use sum(abs2, x) instead.\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1msumabs2\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Float64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:57\u001b[22m\u001b[22m\n",
      " [3] \u001b[1mevaluate\u001b[22m\u001b[22m at \u001b[1m/////////mnt/juliabox/.julia/v0.6/LowRankModels/src/regularizers.jl:57\u001b[22m\u001b[22m [inlined]\n",
      " [4] \u001b[1m#proxgrad_linesearch#6\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Int64, ::Int64, ::Array{Float64,1}, ::LowRankModels.ConvergenceHistory, ::Function, ::LowRankModels.QuadLoss, ::LowRankModels.QuadReg, ::Array{Float64,2}, ::Array{Int64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./In[7]:36\u001b[22m\u001b[22m\n",
      " [5] \u001b[1m(::#kw##proxgrad_linesearch)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::#proxgrad_linesearch, ::LowRankModels.QuadLoss, ::LowRankModels.QuadReg, ::Array{Float64,2}, ::Array{Int64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m\n",
      " [6] \u001b[1m#proxgrad#5\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Function, ::LowRankModels.QuadLoss, ::LowRankModels.QuadReg, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./In[7]:23\u001b[22m\u001b[22m\n",
      " [7] \u001b[1m(::#kw##proxgrad)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::#proxgrad, ::LowRankModels.QuadLoss, ::LowRankModels.QuadReg, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m\n",
      " [8] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m\n",
      " [9] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/////////mnt/juliabox/.julia/v0.6/Compat/src/Compat.jl:478\u001b[22m\u001b[22m\n",
      " [10] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/jrun/.julia/v0.6/IJulia/src/execute_request.jl:154\u001b[22m\u001b[22m\n",
      " [11] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/jrun/.julia/v0.6/IJulia/src/eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [12] \u001b[1m(::IJulia.##14#17)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[72], in expression starting on line 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       "  0.0143044 \n",
       " -0.00726158\n",
       "  0.0207852 \n",
       " -0.0206557 \n",
       "  0.00134724"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_ridge = proxgrad(QuadLoss(), QuadReg(), X, y, maxiters=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30919220055710306\n",
      "338.91344883383545\n"
     ]
    }
   ],
   "source": [
    "test_pred = sign.(testX*w_ridge)\n",
    "println(errorRate(testX*w_ridge, testy))\n",
    "println(squaredError(testX*w_ridge, testy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33msumabs(x) is deprecated, use sum(abs, x) instead.\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1msumabs\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Float64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:57\u001b[22m\u001b[22m\n",
      " [3] \u001b[1mevaluate\u001b[22m\u001b[22m at \u001b[1m/////////mnt/juliabox/.julia/v0.6/LowRankModels/src/regularizers.jl:87\u001b[22m\u001b[22m [inlined]\n",
      " [4] \u001b[1m#proxgrad_linesearch#6\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Int64, ::Int64, ::Array{Float64,1}, ::LowRankModels.ConvergenceHistory, ::Function, ::LowRankModels.QuadLoss, ::LowRankModels.OneReg, ::Array{Float64,2}, ::Array{Int64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./In[7]:36\u001b[22m\u001b[22m\n",
      " [5] \u001b[1m(::#kw##proxgrad_linesearch)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::#proxgrad_linesearch, ::LowRankModels.QuadLoss, ::LowRankModels.OneReg, ::Array{Float64,2}, ::Array{Int64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m\n",
      " [6] \u001b[1m#proxgrad#5\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Function, ::LowRankModels.QuadLoss, ::LowRankModels.OneReg, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./In[7]:23\u001b[22m\u001b[22m\n",
      " [7] \u001b[1m(::#kw##proxgrad)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::#proxgrad, ::LowRankModels.QuadLoss, ::LowRankModels.OneReg, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m\n",
      " [8] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m\n",
      " [9] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/////////mnt/juliabox/.julia/v0.6/Compat/src/Compat.jl:478\u001b[22m\u001b[22m\n",
      " [10] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/jrun/.julia/v0.6/IJulia/src/execute_request.jl:154\u001b[22m\u001b[22m\n",
      " [11] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/jrun/.julia/v0.6/IJulia/src/eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [12] \u001b[1m(::IJulia.##14#17)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[74], in expression starting on line 1\n",
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mmax{T1 <: Real}(x::AbstractArray{T1}, y::Real) is deprecated, use max.(x, y) instead.\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1mmax\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Float64,1}, ::Int64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:57\u001b[22m\u001b[22m\n",
      " [3] \u001b[1mprox\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::LowRankModels.OneReg, ::Array{Float64,1}, ::Int64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/////////mnt/juliabox/.julia/v0.6/LowRankModels/src/regularizers.jl:82\u001b[22m\u001b[22m\n",
      " [4] \u001b[1m#proxgrad_linesearch#6\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Int64, ::Int64, ::Array{Float64,1}, ::LowRankModels.ConvergenceHistory, ::Function, ::LowRankModels.QuadLoss, ::LowRankModels.OneReg, ::Array{Float64,2}, ::Array{Int64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./In[7]:42\u001b[22m\u001b[22m\n",
      " [5] \u001b[1m(::#kw##proxgrad_linesearch)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::#proxgrad_linesearch, ::LowRankModels.QuadLoss, ::LowRankModels.OneReg, ::Array{Float64,2}, ::Array{Int64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m\n",
      " [6] \u001b[1m#proxgrad#5\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Function, ::LowRankModels.QuadLoss, ::LowRankModels.OneReg, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./In[7]:23\u001b[22m\u001b[22m\n",
      " [7] \u001b[1m(::#kw##proxgrad)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::#proxgrad, ::LowRankModels.QuadLoss, ::LowRankModels.OneReg, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m\n",
      " [8] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m\n",
      " [9] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/////////mnt/juliabox/.julia/v0.6/Compat/src/Compat.jl:478\u001b[22m\u001b[22m\n",
      " [10] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/jrun/.julia/v0.6/IJulia/src/execute_request.jl:154\u001b[22m\u001b[22m\n",
      " [11] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/jrun/.julia/v0.6/IJulia/src/eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [12] \u001b[1m(::IJulia.##14#17)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[74], in expression starting on line 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       "  0.0143042 \n",
       " -0.00726146\n",
       "  0.0207851 \n",
       " -0.0206556 \n",
       "  0.00134711"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_lasso = proxgrad(QuadLoss(), OneReg(), X, y, maxiters=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30919220055710306\n",
      "338.9135139125289\n"
     ]
    }
   ],
   "source": [
    "test_pred = sign.(testX*w_lasso)\n",
    "println(errorRate(testX*w_lasso, testy))\n",
    "println(squaredError(testX*w_lasso, testy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# l1 regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       "  0.0176902 \n",
       " -0.00838146\n",
       "  0.032531  \n",
       " -0.0296652 \n",
       "  0.00091361"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_l1 = proxgrad(L1Loss(), ZeroReg(), X, y, maxiters=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49025069637883006\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mMethodError: no method matching *(::Array{Float64,2}, ::LowRankModels.#l1)\u001b[0m\nClosest candidates are:\n  *(::Any, ::Any, \u001b[91m::Any\u001b[39m, \u001b[91m::Any...\u001b[39m) at operators.jl:424\n  *(::Union{Base.ReshapedArray{T<:Union{Complex{Float32}, Complex{Float64}, Float32, Float64},2,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:DenseArray, DenseArray{T<:Union{Complex{Float32}, Complex{Float64}, Float32, Float64},2}, SubArray{T<:Union{Complex{Float32}, Complex{Float64}, Float32, Float64},2,A,I,L} where L} where I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex, Int64, Range{Int64}},N} where N} where A<:Union{Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:DenseArray where N where T, DenseArray}, \u001b[91m::Union{Base.ReshapedArray{S,1,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:DenseArray, DenseArray{S,1}, SubArray{S,1,A,I,L} where L} where I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex, Int64, Range{Int64}},N} where N} where A<:Union{Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:DenseArray where N where T, DenseArray}\u001b[39m) where {T<:Union{Complex{Float32}, Complex{Float64}, Float32, Float64}, S} at linalg/matmul.jl:74\n  *(::Union{Base.ReshapedArray{T,2,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:DenseArray, DenseArray{T,2}, SubArray{T,2,A,I,L} where L} where I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex, Int64, Range{Int64}},N} where N} where A<:Union{Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:DenseArray where N where T, DenseArray} where T, \u001b[91m::Union{Base.LinAlg.QRCompactWYQ, Base.LinAlg.QRPackedQ}\u001b[39m) at linalg/qr.jl:627\n  ...\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mMethodError: no method matching *(::Array{Float64,2}, ::LowRankModels.#l1)\u001b[0m\nClosest candidates are:\n  *(::Any, ::Any, \u001b[91m::Any\u001b[39m, \u001b[91m::Any...\u001b[39m) at operators.jl:424\n  *(::Union{Base.ReshapedArray{T<:Union{Complex{Float32}, Complex{Float64}, Float32, Float64},2,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:DenseArray, DenseArray{T<:Union{Complex{Float32}, Complex{Float64}, Float32, Float64},2}, SubArray{T<:Union{Complex{Float32}, Complex{Float64}, Float32, Float64},2,A,I,L} where L} where I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex, Int64, Range{Int64}},N} where N} where A<:Union{Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:DenseArray where N where T, DenseArray}, \u001b[91m::Union{Base.ReshapedArray{S,1,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:DenseArray, DenseArray{S,1}, SubArray{S,1,A,I,L} where L} where I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex, Int64, Range{Int64}},N} where N} where A<:Union{Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:DenseArray where N where T, DenseArray}\u001b[39m) where {T<:Union{Complex{Float32}, Complex{Float64}, Float32, Float64}, S} at linalg/matmul.jl:74\n  *(::Union{Base.ReshapedArray{T,2,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:DenseArray, DenseArray{T,2}, SubArray{T,2,A,I,L} where L} where I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex, Int64, Range{Int64}},N} where N} where A<:Union{Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:DenseArray where N where T, DenseArray} where T, \u001b[91m::Union{Base.LinAlg.QRCompactWYQ, Base.LinAlg.QRPackedQ}\u001b[39m) at linalg/qr.jl:627\n  ...\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "test_pred = sign.(testX*w_l1)\n",
    "println(errorRate(testX*w_l1, testy))\n",
    "println(squaredError(testX*w_l1, testy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# huber regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       "  0.000216319\n",
       " -0.000119129\n",
       "  0.00244823 \n",
       "  0.00153871 \n",
       "  4.19456e-6 "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_huber = proxgrad(HuberLoss(), ZeroReg(), X, y, maxiters=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5069637883008357\n",
      "418.9386084894679\n"
     ]
    }
   ],
   "source": [
    "test_pred = sign.(testX*w_huber)\n",
    "println(errorRate(testX*w_huber, testy))\n",
    "println(squaredError(testX*w_huber, testy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33msumabs2(x) is deprecated, use sum(abs2, x) instead.\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1msumabs2\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Float64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:57\u001b[22m\u001b[22m\n",
      " [3] \u001b[1mevaluate\u001b[22m\u001b[22m at \u001b[1m/////////mnt/juliabox/.julia/v0.6/LowRankModels/src/regularizers.jl:57\u001b[22m\u001b[22m [inlined]\n",
      " [4] \u001b[1m#proxgrad_linesearch#6\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Int64, ::Int64, ::Array{Float64,1}, ::LowRankModels.ConvergenceHistory, ::Function, ::LowRankModels.LogisticLoss, ::LowRankModels.QuadReg, ::Array{Float64,2}, ::Array{Int64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./In[7]:36\u001b[22m\u001b[22m\n",
      " [5] \u001b[1m(::#kw##proxgrad_linesearch)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::#proxgrad_linesearch, ::LowRankModels.LogisticLoss, ::LowRankModels.QuadReg, ::Array{Float64,2}, ::Array{Int64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m\n",
      " [6] \u001b[1m#proxgrad#5\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Function, ::LowRankModels.LogisticLoss, ::LowRankModels.QuadReg, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./In[7]:23\u001b[22m\u001b[22m\n",
      " [7] \u001b[1m(::#kw##proxgrad)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::#proxgrad, ::LowRankModels.LogisticLoss, ::LowRankModels.QuadReg, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m\n",
      " [8] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m\n",
      " [9] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/////////mnt/juliabox/.julia/v0.6/Compat/src/Compat.jl:478\u001b[22m\u001b[22m\n",
      " [10] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/jrun/.julia/v0.6/IJulia/src/execute_request.jl:154\u001b[22m\u001b[22m\n",
      " [11] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/jrun/.julia/v0.6/IJulia/src/eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [12] \u001b[1m(::IJulia.##14#17)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[80], in expression starting on line 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       "  0.0288396 \n",
       " -0.0147028 \n",
       "  0.0422295 \n",
       " -0.0419693 \n",
       "  0.00270916"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_logistic = proxgrad(LogisticLoss(), QuadReg(), X, y, maxiters=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30919220055710306\n",
      "329.0205457559514\n"
     ]
    }
   ],
   "source": [
    "test_pred = sign.(testX*w_logistic)\n",
    "println(errorRate(testX*w_logistic, testy))\n",
    "println(squaredError(testX*w_logistic, testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       "  0.0288396 \n",
       " -0.0147028 \n",
       "  0.0422296 \n",
       " -0.0419694 \n",
       "  0.00270916"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_logistic = proxgrad(LogisticLoss(), ZeroReg(), X, y, maxiters=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30919220055710306\n",
      "329.0205374123414\n"
     ]
    }
   ],
   "source": [
    "test_pred = sign.(testX*w_logistic)\n",
    "println(errorRate(testX*w_logistic, testy))\n",
    "println(squaredError(testX*w_logistic, testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
